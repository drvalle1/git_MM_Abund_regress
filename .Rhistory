summary(xmods[[ind]])
z[order(z$AIC),]
set.seed(1)
n=100
habitat.type=sample(1:8,size=n,replace=T)
xmat=matrix(0,7)
colnames(xmat)=paste('x',1:7,sep='')
for (i in 1:7){ #habitat type 8 is the baseline habitat type
cond=habitat.type==i
xmat[cond,i]=1
}
unique(cbind(xmat,habitat.type))
set.seed(1)
n=100
habitat.type=sample(1:8,size=n,replace=T)
xmat=matrix(0,n,7)
colnames(xmat)=paste('x',1:7,sep='')
for (i in 1:7){ #habitat type 8 is the baseline habitat type
cond=habitat.type==i
xmat[cond,i]=1
}
unique(cbind(xmat,habitat.type))
set.seed(1)
n=100
habitat.type=sort(sample(1:8,size=n,replace=T))
xmat=matrix(0,n,7)
colnames(xmat)=paste('x',1:7,sep='')
for (i in 1:7){ #habitat type 8 is the baseline habitat type
cond=habitat.type==i
xmat[cond,i]=1
}
unique(cbind(xmat,habitat.type))
?chisq.test
# rm(list=ls(all=TRUE))
library('Rcpp')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_LDA_fungi_regression')
source('gibbs functions.R')
sourceCpp('aux1.cpp')
#get data
setwd('U:\\GIT_models\\git_LDA_fungi_regression\\fake data')
dat=read.csv('fake data 4.csv',as.is=T)
head(dat)
# rm(list=ls(all=TRUE))
library('Rcpp')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_MM_Abund_regress')
source('gibbs functions.R')
sourceCpp('aux1.cpp')
#get data
dat=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(dat)=='X')
y=data.matrix(dat[,-ind]); dim(y)
xmat=data.matrix(read.csv('fake data xmat4.csv',as.is=T))
head(dat)
rm(list=ls(all=TRUE))
library('Rcpp')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_MM_Abund_regress')
source('gibbs functions.R')
sourceCpp('aux1.cpp')
#get data
dat=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(dat)=='X')
y=data.matrix(dat[,-ind]); dim(y)
xmat=data.matrix(read.csv('fake data xmat4.csv',as.is=T))
#useful stuff
ncomm=4
hi=0.999999
lo=0.000001
nspp=ncol(y)
nloc=nrow(y)
npar=ncol(xmat)
txmat=t(xmat)
xtx=txmat%*%xmat
#initial values of parameters
betas=matrix(0,npar,ncomm-1)
omega=matrix(0,nloc,ncomm)
theta=matrix(1/ncomm,nloc,ncomm)
phi=matrix(1/nspp,ncomm,nspp)
sig2=1
#priors
a.sig2=nloc*(ncomm-1)/2
b.sig2=nloc*(ncomm-1)/200
#gibbs details
ngibbs=1000
#objects to store gibbs output
theta.out=matrix(NA,ngibbs,ncomm*nloc)
phi.out=matrix(NA,ngibbs,ncomm*nspp)
betas.out=matrix(NA,ngibbs,npar*(ncomm-1))
sig2.out=matrix(NA,ngibbs,1)
llk=rep(NA,ngibbs)
#MH stuff
accept.output=50
jump1=list(omega=matrix(1,nloc,ncomm))
accept1=list(omega=matrix(0,nloc,ncomm))
#gibbs sampler
options(warn=2)
for (i in 1:ngibbs){
print(i)
#get omega and theta (after integrating out the z's)
tmp=get.omega.theta(y=y,sig2=sig2,ncomm=ncomm,nloc=nloc,
omega=omega,xmat=xmat,betas=betas,phi=phi,jump=jump1$omega)
omega=tmp$omega
theta=tmp$theta
accept1$omega=accept1$omega+tmp$accept
theta[theta>hi]=hi; theta[theta<lo]=lo
# omega=omega.true
# theta=theta.true
#sample z
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
# nlk=nlk.true
nks=tmp$nks
# nks=nks.true
#sample phi
phi=rdirichlet1(alpha=nks+1,ncomm=ncomm,nspp=nspp)
phi[phi>hi]=hi; phi[phi<lo]=lo
phi[,4]=c(0,0,0,0.0852488) #this ensures that estimated=true last community
# phi=phi.true
#sample regression coefficients betas
betas=get.betas(xtx=xtx,sig2=sig2,omega=omega,nparam=npar,
ncomm=ncomm,txmat=txmat)
#sample sig2
sig2=get.sig2(nloc=nloc,ncomm=ncomm,xmat=xmat,betas=betas,
omega=omega,a.sig2=a.sig2,b.sig2=b.sig2)
#adaptation of MH algorithm
if (i%%accept.output==0 & i<1000){
k=print.adapt(accept1z=accept1,jump1z=jump1,accept.output=accept.output)
accept1=k$accept1
jump1=k$jump1
}
#calculate loglikelihood
prob=theta%*%phi
prob[prob>hi]=hi; prob[prob<lo]=lo
#store results
llk[i]=sum(y*log(prob))
theta.out[i,]=theta
phi.out[i,]=phi
betas.out[i,]=betas
sig2.out[i]=sig2
}
head(theta)
sig2
plot(sig2.out,type='l')
abline(v=0.01,col='red')
abline(h=0.01,col='red')
betas
boxplot(theta)
ind=1:4
ind=c(3,2,1,4)
theta1=theta[,ind]
par(mfrow=c(2,2))
for (i in 1:4) plot(theta.true[,i],theta1[,i])
set.seed(4)
nloc=1000
nspp=100
ncommun=4
#generate thetas (each community should dominate in at least some place)
tmp1=c(seq(from=2,to=0,length.out=nloc/2),rep(0,nloc*1/2))
tmp2=c(rep(0,nloc/8),seq(from=0,to=2,length.out=nloc/8),seq(from=2,to=0,length.out=nloc/8),rep(0,nloc*5/8))
tmp3=c(rep(0,nloc/4),seq(from=0,to=2,length.out=nloc/8),seq(from=2,to=0,length.out=nloc/8),rep(0,nloc*4/8))
xmat=cbind(1,tmp1,tmp2,tmp3)
colnames(xmat)=c('interc',paste('cov',1:3,sep=''))
betas=matrix(0,ncol(xmat),ncommun-1)
betas[,1]=c(-3,4,0,0)
betas[,2]=c(-3,0,4,0)
betas[,3]=c(-3,0,0,4)
betas.true=betas
sig2=0.1
media=xmat%*%betas; range(media)
eres=cbind(exp(media),1)
theta.pred=eres/rowSums(eres)
plot(NA,NA,xlim=c(0,nloc),ylim=range(theta.pred))
for (i in 1:ncommun) lines(1:nloc,theta.pred[,i],col=i)
image(media)
omega=matrix(NA,nloc,ncommun)
omega[,ncommun]=0
for (i in 1:(ncommun-1)){
omega[,i]=rnorm(nloc,mean=media[,i],sd=sqrt(sig2))
}
omega.true=omega
range(omega)
e.omega=exp(omega)
soma=rowSums(e.omega)
theta.true=theta=e.omega/matrix(soma,nloc,ncommun)
apply(theta,1,sum)
plot(NA,NA,xlim=c(0,nloc),ylim=c(0,1))
for (i in 1:ncommun) lines(1:nloc,theta[,i],col=i)
#generate phi
tmp=matrix(rnorm(ncommun*nspp,mean=0,sd=2),ncommun,nspp)
tmp[tmp<0.1]=0.1
tmp[,1:(2*ncommun)]=cbind(diag(8,ncommun),diag(8,ncommun))
phi=tmp/matrix(rowSums(tmp),ncommun,nspp)
round(phi[,1:20],2)
table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
#generate actual observations y
nl=floor(runif(nloc,min=100,max=200))
nlk=matrix(NA,nloc,ncommun)
nks=matrix(0,ncommun,nspp)
y=matrix(NA,nloc,nspp)
for (i in 1:nloc){
nlk[i,]=rmultinom(1,size=nl[i],prob=theta[i,])
tmp1=rep(0,ncommun)
for (k in 1:ncommun){
tmp=rmultinom(1,size=nlk[i,k],prob=phi[k,])
nks[k,]=nks[k,]+tmp
tmp1=tmp1+tmp
}
y[i,]=tmp1
}
image(y)
#look at stuff to make sure it makes sense
theta.estim=nlk/matrix(nl,nloc,ncommun)
plot(NA,NA,xlim=c(1,nloc),ylim=c(0,1))
for (i in 1:ncommun) lines(1:nloc,theta.estim[,i],col=i)
nlk.true=nlk
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp,)
plot(phi.true,phi.estim)
nks.true=nks
ind=1:4
ind=c(3,2,1,4)
theta1=theta[,ind]
par(mfrow=c(2,2))
for (i in 1:4) plot(theta.true[,i],theta1[,i])
theta=matrix(theta.out[ngibbs,],nloc,ncommun)
ind=1:4
ind=c(3,2,1,4)
theta1=theta[,ind]
par(mfrow=c(2,2))
for (i in 1:4) plot(theta.true[,i],theta1[,i])
betas
rm(list=ls(all=TRUE))
set.seed(4)
nloc=1000
nspp=100
ncommun=4
#generate thetas (each community should dominate in at least some place)
tmp1=c(seq(from=2,to=0,length.out=nloc/2),rep(0,nloc*1/2))
tmp2=c(rep(0,nloc/8),seq(from=0,to=2,length.out=nloc/8),seq(from=2,to=0,length.out=nloc/8),rep(0,nloc*5/8))
tmp3=c(rep(0,nloc/4),seq(from=0,to=2,length.out=nloc/8),seq(from=2,to=0,length.out=nloc/8),rep(0,nloc*4/8))
xmat=cbind(1,tmp1,tmp2,tmp3)
colnames(xmat)=c('interc',paste('cov',1:3,sep=''))
betas=matrix(0,ncol(xmat),ncommun-1)
betas[,1]=c(-3,4,0,0)
betas[,2]=c(-3,0,4,0)
betas[,3]=c(-3,0,0,4)
betas.true=betas
sig2=0.1
media=xmat%*%betas; range(media)
eres=cbind(exp(media),1)
theta.pred=eres/rowSums(eres)
plot(NA,NA,xlim=c(0,nloc),ylim=range(theta.pred))
for (i in 1:ncommun) lines(1:nloc,theta.pred[,i],col=i)
image(media)
omega=matrix(NA,nloc,ncommun)
omega[,ncommun]=0
for (i in 1:(ncommun-1)){
omega[,i]=rnorm(nloc,mean=media[,i],sd=sqrt(sig2))
}
omega.true=omega
range(omega)
e.omega=exp(omega)
soma=rowSums(e.omega)
theta.true=theta=e.omega/matrix(soma,nloc,ncommun)
apply(theta,1,sum)
plot(NA,NA,xlim=c(0,nloc),ylim=c(0,1))
for (i in 1:ncommun) lines(1:nloc,theta[,i],col=i)
#generate phi
tmp=matrix(rnorm(ncommun*nspp,mean=0,sd=2),ncommun,nspp)
tmp[tmp<0.1]=0.1
tmp[,1:(2*ncommun)]=cbind(diag(8,ncommun),diag(8,ncommun))
phi=tmp/matrix(rowSums(tmp),ncommun,nspp)
round(phi[,1:20],2)
table(round(phi,2))
unique(rowSums(phi))
phi.true=phi
#generate actual observations y
nl=floor(runif(nloc,min=100,max=200))
nlk=matrix(NA,nloc,ncommun)
nks=matrix(0,ncommun,nspp)
y=matrix(NA,nloc,nspp)
for (i in 1:nloc){
nlk[i,]=rmultinom(1,size=nl[i],prob=theta[i,])
tmp1=rep(0,ncommun)
for (k in 1:ncommun){
tmp=rmultinom(1,size=nlk[i,k],prob=phi[k,])
nks[k,]=nks[k,]+tmp
tmp1=tmp1+tmp
}
y[i,]=tmp1
}
image(y)
#look at stuff to make sure it makes sense
theta.estim=nlk/matrix(nl,nloc,ncommun)
plot(NA,NA,xlim=c(1,nloc),ylim=c(0,1))
for (i in 1:ncommun) lines(1:nloc,theta.estim[,i],col=i)
nlk.true=nlk
phi.estim=nks/matrix(rowSums(nks),ncommun,nspp,)
plot(phi.true,phi.estim)
nks.true=nks
#export results
setwd('U:\\GIT_models\\git_MM_Abund_regress')
nome=paste(c('fake data','fake data xmat'),ncommun,'.csv',sep='')
colnames(y)=paste('spp',1:nspp,sep='')
rownames(y)=paste('loc',1:nloc,sep='')
write.csv(y,nome[1])
write.csv(xmat,nome[2],row.names=F)
library('Rcpp')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_MM_Abund_regress')
source('gibbs functions.R')
sourceCpp('aux1.cpp')
#get data
dat=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(dat)=='X')
y=data.matrix(dat[,-ind]); dim(y)
xmat=data.matrix(read.csv('fake data xmat4.csv',as.is=T))
#useful stuff
ncomm=4
hi=0.999999
lo=0.000001
nspp=ncol(y)
nloc=nrow(y)
npar=ncol(xmat)
txmat=t(xmat)
xtx=txmat%*%xmat
#initial values of parameters
betas=matrix(0,npar,ncomm-1)
omega=matrix(0,nloc,ncomm)
theta=matrix(1/ncomm,nloc,ncomm)
phi=matrix(1/nspp,ncomm,nspp)
sig2=1
#priors
a.sig2=nloc*(ncomm-1)/2
b.sig2=nloc*(ncomm-1)/200
#gibbs details
ngibbs=1000
#objects to store gibbs output
theta.out=matrix(NA,ngibbs,ncomm*nloc)
phi.out=matrix(NA,ngibbs,ncomm*nspp)
betas.out=matrix(NA,ngibbs,npar*(ncomm-1))
sig2.out=matrix(NA,ngibbs,1)
llk=rep(NA,ngibbs)
#MH stuff
accept.output=50
jump1=list(omega=matrix(1,nloc,ncomm))
accept1=list(omega=matrix(0,nloc,ncomm))
#gibbs sampler
options(warn=2)
for (i in 1:ngibbs){
print(i)
#get omega and theta (after integrating out the z's)
tmp=get.omega.theta(y=y,sig2=sig2,ncomm=ncomm,nloc=nloc,
omega=omega,xmat=xmat,betas=betas,phi=phi,jump=jump1$omega)
omega=tmp$omega
theta=tmp$theta
accept1$omega=accept1$omega+tmp$accept
theta[theta>hi]=hi; theta[theta<lo]=lo
# omega=omega.true
# theta=theta.true
#sample z
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
# nlk=nlk.true
nks=tmp$nks
# nks=nks.true
#sample phi
phi=rdirichlet1(alpha=nks+1,ncomm=ncomm,nspp=nspp)
phi[phi>hi]=hi; phi[phi<lo]=lo
phi[,4]=c(0,0,0,0.0852488) #this ensures that estimated=true last community
# phi=phi.true
#sample regression coefficients betas
betas=get.betas(xtx=xtx,sig2=sig2,omega=omega,nparam=npar,
ncomm=ncomm,txmat=txmat)
#sample sig2
sig2=get.sig2(nloc=nloc,ncomm=ncomm,xmat=xmat,betas=betas,
omega=omega,a.sig2=a.sig2,b.sig2=b.sig2)
#adaptation of MH algorithm
if (i%%accept.output==0 & i<1000){
k=print.adapt(accept1z=accept1,jump1z=jump1,accept.output=accept.output)
accept1=k$accept1
jump1=k$jump1
}
#calculate loglikelihood
prob=theta%*%phi
prob[prob>hi]=hi; prob[prob<lo]=lo
#store results
llk[i]=sum(y*log(prob))
theta.out[i,]=theta
phi.out[i,]=phi
betas.out[i,]=betas
sig2.out[i]=sig2
}
ind=1:4
ind=c(3,2,1,4)
theta1=theta[,ind]
par(mfrow=c(2,2))
for (i in 1:4) plot(theta.true[,i],theta1[,i])
betas
ind=c(3,1,2,4)
theta1=theta[,ind]
par(mfrow=c(2,2))
for (i in 1:4) plot(theta.true[,i],theta1[,i])
plot(phi.true,phi[ind,])
betas1=betas[,ind[1:3]]
plot(betas.true,betas1)
plot(sig2.out,type='l')
library('Rcpp')
set.seed(4)
#get functions
setwd('U:\\GIT_models\\git_MM_Abund_regress')
source('gibbs functions.R')
sourceCpp('aux1.cpp')
#get data
dat=read.csv('fake data4.csv',as.is=T)
ind=which(colnames(dat)=='X')
y=data.matrix(dat[,-ind]); dim(y)
xmat=data.matrix(read.csv('fake data xmat4.csv',as.is=T))
#useful stuff
ncomm=4
hi=0.999999
lo=0.000001
nspp=ncol(y)
nloc=nrow(y)
npar=ncol(xmat)
txmat=t(xmat)
xtx=txmat%*%xmat
#initial values of parameters
betas=matrix(0,npar,ncomm-1)
omega=matrix(0,nloc,ncomm)
theta=matrix(1/ncomm,nloc,ncomm)
phi=matrix(1/nspp,ncomm,nspp)
sig2=1
#priors
a.sig2=0.1#nloc*(ncomm-1)/2
b.sig2=0.1#nloc*(ncomm-1)/200
#gibbs details
ngibbs=1000
#objects to store gibbs output
theta.out=matrix(NA,ngibbs,ncomm*nloc)
phi.out=matrix(NA,ngibbs,ncomm*nspp)
betas.out=matrix(NA,ngibbs,npar*(ncomm-1))
sig2.out=matrix(NA,ngibbs,1)
llk=rep(NA,ngibbs)
#MH stuff
accept.output=50
jump1=list(omega=matrix(1,nloc,ncomm))
accept1=list(omega=matrix(0,nloc,ncomm))
#gibbs sampler
options(warn=2)
for (i in 1:ngibbs){
print(i)
#get omega and theta (after integrating out the z's)
tmp=get.omega.theta(y=y,sig2=sig2,ncomm=ncomm,nloc=nloc,
omega=omega,xmat=xmat,betas=betas,phi=phi,jump=jump1$omega)
omega=tmp$omega
theta=tmp$theta
accept1$omega=accept1$omega+tmp$accept
theta[theta>hi]=hi; theta[theta<lo]=lo
# omega=omega.true
# theta=theta.true
#sample z
tmp=samplez(theta=theta, phi=phi, y=y, ncommun=ncomm, nloc=nloc, nspp=nspp)
nlk=tmp$nlk
# nlk=nlk.true
nks=tmp$nks
# nks=nks.true
#sample phi
phi=rdirichlet1(alpha=nks+1,ncomm=ncomm,nspp=nspp)
phi[phi>hi]=hi; phi[phi<lo]=lo
phi[,4]=c(0,0,0,0.0852488) #this ensures that estimated=true last community
# phi=phi.true
#sample regression coefficients betas
betas=get.betas(xtx=xtx,sig2=sig2,omega=omega,nparam=npar,
ncomm=ncomm,txmat=txmat)
#sample sig2
sig2=get.sig2(nloc=nloc,ncomm=ncomm,xmat=xmat,betas=betas,
omega=omega,a.sig2=a.sig2,b.sig2=b.sig2)
#adaptation of MH algorithm
if (i%%accept.output==0 & i<1000){
k=print.adapt(accept1z=accept1,jump1z=jump1,accept.output=accept.output)
accept1=k$accept1
jump1=k$jump1
}
#calculate loglikelihood
prob=theta%*%phi
prob[prob>hi]=hi; prob[prob<lo]=lo
#store results
llk[i]=sum(y*log(prob))
theta.out[i,]=theta
phi.out[i,]=phi
betas.out[i,]=betas
sig2.out[i]=sig2
}
plot(sig2.out,type='l')
betas
ind=c(3,1,2,4)
theta1=theta[,ind]
par(mfrow=c(2,2))
for (i in 1:4) plot(theta.true[,i],theta1[,i])
plot(phi.true,phi[ind,])
betas1=betas[,ind[1:3]]
plot(betas.true,betas1)
plot(sig2.out,type='l')
abline(h=0.1,col='red')
